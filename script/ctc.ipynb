{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "\n",
    "from main.inference import ContextRegularizedGenerator\n",
    "from audio_diffusion_pytorch import KarrasSchedule\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59070/4169867572.py:1: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=\"../exp\"):\n"
     ]
    }
   ],
   "source": [
    "with initialize(config_path=\"../exp\"):\n",
    "    cfg = compose(config_name=\"base_slakh_1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    if path.endswith('ckpt'):\n",
    "        state_dict = torch.load(path)['state_dict']\n",
    "    else:\n",
    "        state_dict = torch.load(path)\n",
    "    model = hydra.utils.instantiate(cfg.model)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "sampling_rate = 22050\n",
    "\n",
    "# @markdown Generation length in seconds (will be rounded to be a power of 2 of sample_rate*length)\n",
    "length = 10\n",
    "length_samples = 2**math.ceil(math.log2(length * sampling_rate))\n",
    "\n",
    "# @markdown Number of samples to generate\n",
    "num_samples = 1\n",
    "\n",
    "# @markdown Number of diffusion steps (higher tends to be better but takes longer to generate)\n",
    "num_steps = 100\n",
    "\n",
    "smin = 1e-4\n",
    "smax = 1.0\n",
    "rho = 7.0\n",
    "\n",
    "sigma_schedule=KarrasSchedule(sigma_min=smin, sigma_max=smax, rho=rho)\n",
    "\n",
    "model_piano = load_model(\"../logs/ckpts/piano-vital-sun-29_epoch880.ckpt\")\n",
    "model_drums = load_model(\"../logs/ckpts/drums-lunar-blaze-24_epoch933.pt\")\n",
    "model_mix = load_model(\"../logs/ckpts/frosty-waterfall-235-epoch=328.ckpt\")\n",
    "\n",
    "cr_generator = ContextRegularizedGenerator(stem_to_model={'drums': model_drums,\n",
    "                                                       'piano': model_drums,\n",
    "                                                       'mixture': model_drums},\n",
    "                                           sigma_schedule=sigma_schedule)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from audio_diffusion_pytorch import KarrasSampler\n",
    "\n",
    "noise = torch.randn(1, 1, 2**18)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_piano = model_piano.model.sample(\n",
    "    noise.cuda(),\n",
    "    num_steps=40\n",
    ")\n",
    "\n",
    "# sample_drums = model_drums.model.sample(\n",
    "#     noise.cuda(),\n",
    "#     num_steps=20\n",
    "# )\n",
    "\n",
    "# sample_mix = model_mix.model.sample(\n",
    "#     noise.cuda(),\n",
    "#    num_steps=20\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "output = cr_generator.generate(1, cfg.length, num_steps=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "torchaudio.save(f\"drums.wav\", output['drums'].reshape(1,-1).cpu(), 22050)\n",
    "torchaudio.save(f\"piano.wav\", output['piano'].reshape(1,-1).cpu(), 22050)\n",
    "torchaudio.save(f\"mixture.wav\", output['mixture'].reshape(1, -1).cpu(), 22050)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
